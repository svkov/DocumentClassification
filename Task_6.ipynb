{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Данные в [архиве](https://drive.google.com/file/d/15o7fdxTgndoy6K-e7g8g1M2-bOOwqZPl/view?usp=sharing). В нём два файла:\n",
    "- `news_train.txt` тренировочное множество\n",
    "- `news_test.txt` тренировочное множество\n",
    "\n",
    "С некоторых новостных сайтов были загружены тексты новостей за период  несколько лет, причем каждая новость принаделжит к какой-то рубрике: `science`, `style`, `culture`, `life`, `economics`, `business`, `travel`, `forces`, `media`, `sport`.\n",
    "\n",
    "В каждой строке файла содержится метка рубрики, заголовок новостной статьи и сам текст статьи, например:\n",
    "\n",
    ">    **sport**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею разгромила чехов**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею крупно об...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "1. Обработать данные, получив для каждого текста набор токенов\n",
    "Обработать токены с помощью (один вариант из трех):\n",
    "    - pymorphy2\n",
    "    - русского [snowball стеммера](https://www.nltk.org/howto/stem.html)\n",
    "    - [SentencePiece](https://github.com/google/sentencepiece) или [Huggingface Tokenizers](https://github.com/huggingface/tokenizers)\n",
    "    \n",
    "    \n",
    "2. Обучить word embeddings (fastText, word2vec, gloVe) на тренировочных данных. Можно использовать [gensim](https://radimrehurek.com/gensim/models/word2vec.html) . Продемонстрировать семантические ассоциации. \n",
    "\n",
    "3. Реализовать алгоритм классификации, посчитать точноть на тестовых данных, подобрать гиперпараметры. Метод векторизации выбрать произвольно - можно использовать $tf-idf$ с понижением размерности (см. scikit-learn), можно использовать обученные на предыдущем шаге векторные представления, можно использовать [предобученные модели](https://rusvectores.org/ru/models/). Имейте ввиду, что простое \"усреднение\" токенов в тексте скорее всего не даст положительных результатов. Нужно реализовать два алгоритмов из трех:\n",
    "     - SVM\n",
    "     - наивный байесовский классификатор\n",
    "     - логистическая регрессия\n",
    "    \n",
    "\n",
    "4.* Реализуйте классификацию с помощью нейросетевых моделей. Например [RuBERT](http://docs.deeppavlov.ai/en/master/features/models/bert.html) или [ELMo](https://rusvectores.org/ru/models/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import re\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Прочитаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list(open('data/news/news_train.txt', 'r', encoding='utf-8'))\n",
    "random.shuffle(lines)\n",
    "c = Counter([line.split('\\t')[0] for line in lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>header</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forces</td>\n",
       "      <td>Под Вязьмой упал военный вертолет</td>\n",
       "      <td>В Смоленской области совершил жесткую посадку ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>science</td>\n",
       "      <td>Пентагон назвал значительно подорожавшие за го...</td>\n",
       "      <td>По итогам 2011 года ряд крупных оборонных прое...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forces</td>\n",
       "      <td>Минобороны РФ заказало 40 модернизированных ве...</td>\n",
       "      <td>Минобороны РФ и холдинг «Вертолеты России» под...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>media</td>\n",
       "      <td>В \"Родной речи\" сменилось руководство</td>\n",
       "      <td>Управляющий директор агентства \"Родная речь\" Ю...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sport</td>\n",
       "      <td>Россиянин Лесун стал олимпийским чемпионом в с...</td>\n",
       "      <td>Россиянин Александр Лесун выиграл золотую меда...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>media</td>\n",
       "      <td>Южнокорейские поисковики обвинили Google в мон...</td>\n",
       "      <td>Компании NHN Corporation и Daum Communications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>forces</td>\n",
       "      <td>На авиабазе под Воронежем при посадке опрокину...</td>\n",
       "      <td>Фронтовой бомбардировщик Су-34 опрокинулся при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>sport</td>\n",
       "      <td>Тренер сборной России по хоккею поменял вратар...</td>\n",
       "      <td>Ворота сборной России по хоккею в матче чемпио...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>sport</td>\n",
       "      <td>«Ведомости» сообщили о возможном расторжении к...</td>\n",
       "      <td>Задолженность Российского футбольного союза (Р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>forces</td>\n",
       "      <td>Американцы представили компактный тепловизор д...</td>\n",
       "      <td>Американская компания Torrey Pines Logic предс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag                                             header  \\\n",
       "0       forces                  Под Вязьмой упал военный вертолет   \n",
       "1      science  Пентагон назвал значительно подорожавшие за го...   \n",
       "2       forces  Минобороны РФ заказало 40 модернизированных ве...   \n",
       "3        media              В \"Родной речи\" сменилось руководство   \n",
       "4        sport  Россиянин Лесун стал олимпийским чемпионом в с...   \n",
       "...        ...                                                ...   \n",
       "14995    media  Южнокорейские поисковики обвинили Google в мон...   \n",
       "14996   forces  На авиабазе под Воронежем при посадке опрокину...   \n",
       "14997    sport  Тренер сборной России по хоккею поменял вратар...   \n",
       "14998    sport  «Ведомости» сообщили о возможном расторжении к...   \n",
       "14999   forces  Американцы представили компактный тепловизор д...   \n",
       "\n",
       "                                                 content  \n",
       "0      В Смоленской области совершил жесткую посадку ...  \n",
       "1      По итогам 2011 года ряд крупных оборонных прое...  \n",
       "2      Минобороны РФ и холдинг «Вертолеты России» под...  \n",
       "3      Управляющий директор агентства \"Родная речь\" Ю...  \n",
       "4      Россиянин Александр Лесун выиграл золотую меда...  \n",
       "...                                                  ...  \n",
       "14995  Компании NHN Corporation и Daum Communications...  \n",
       "14996  Фронтовой бомбардировщик Су-34 опрокинулся при...  \n",
       "14997  Ворота сборной России по хоккею в матче чемпио...  \n",
       "14998  Задолженность Российского футбольного союза (Р...  \n",
       "14999  Американская компания Torrey Pines Logic предс...  \n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['tag', 'header', 'content'])\n",
    "for i, line in enumerate(lines):\n",
    "    tag, header, content = line.split('\\t')\n",
    "    new_row = pd.DataFrame({'tag': tag, 'header': header, 'content': content}, index=[i])\n",
    "    df = df.append(new_row)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:12000]\n",
    "test = df[12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentences(df):\n",
    "    processed_texts = []\n",
    "    for i, text in enumerate(df['content']):\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        text = text.lower()\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        tokens = [morph.parse(word)[0].normal_form for word in words]\n",
    "        processed_texts.append(tokens)\n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess train...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "Preprocess test...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "Wall time: 16min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Preprocess train...')\n",
    "processed_train = process_sentences(train)\n",
    "print('Preprocess test...')\n",
    "processed_test = process_sentences(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=processed_train, window=5, min_count=1, workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10305884, 11837010)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(processed_train, total_examples=10, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Семантические ассоциации: </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слова, похожие на \"экономика\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('инфляция', 0.866185188293457),\n",
       " ('рост', 0.8463464975357056),\n",
       " ('рецессия', 0.8347263336181641),\n",
       " ('ввп', 0.8345650434494019),\n",
       " ('спад', 0.8315925002098083)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['экономика'], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Путин - президент\n",
    "\n",
    "премьер-министр - ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('медведев', 0.8761460781097412)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['путин', \"премьер\", \"министр\"], negative=['президент'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_pred, y_test):\n",
    "    print(f'Precision: {precision_score(y_pred, y_test, average=\"weighted\"):.2f}')\n",
    "    print(f'Recall: {recall_score(y_pred, y_test, average=\"weighted\"):.2f}')\n",
    "    print(f'F1 score: {f1_score(y_pred, y_test, average=\"weighted\"):.2f}')\n",
    "    print(f'Accuracy: {accuracy_score(y_pred, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [' '.join(sentence) for sentence in processed_train]\n",
    "y_train = train['tag']\n",
    "X_test = [' '.join(sentence) for sentence in processed_test]\n",
    "y_test = test['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = RandomizedSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_distributions={\n",
    "        'C': np.arange(0.01, 1.01, 0.01)\n",
    "    }\n",
    ")\n",
    "\n",
    "naive_bayes = RandomizedSearchCV(\n",
    "    MultinomialNB(),\n",
    "    param_distributions={\n",
    "        'alpha': np.arange(0.5, 1.51, 0.01)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22,\n",
       "       0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33,\n",
       "       0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44,\n",
       "       0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55,\n",
       "       0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66,\n",
       "       0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77,\n",
       "       0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88,\n",
       "       0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99,\n",
       "       1.  ])})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=MultinomialNB(),\n",
       "                   param_distributions={'alpha': array([0.5 , 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6 ,\n",
       "       0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7 , 0.71,\n",
       "       0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8 , 0.81, 0.82,\n",
       "       0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9 , 0.91, 0.92, 0.93,\n",
       "       0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.  , 1.01, 1.02, 1.03, 1.04,\n",
       "       1.05, 1.06, 1.07, 1.08, 1.09, 1.1 , 1.11, 1.12, 1.13, 1.14, 1.15,\n",
       "       1.16, 1.17, 1.18, 1.19, 1.2 , 1.21, 1.22, 1.23, 1.24, 1.25, 1.26,\n",
       "       1.27, 1.28, 1.29, 1.3 , 1.31, 1.32, 1.33, 1.34, 1.35, 1.36, 1.37,\n",
       "       1.38, 1.39, 1.4 , 1.41, 1.42, 1.43, 1.44, 1.45, 1.46, 1.47, 1.48,\n",
       "       1.49, 1.5 ])})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Precision: 0.88\n",
      "Recall: 0.86\n",
      "F1 score: 0.87\n",
      "Accuracy: 0.86\n",
      "\n",
      "Naive Bayes:\n",
      "Precision: 0.87\n",
      "Recall: 0.79\n",
      "F1 score: 0.82\n",
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression:')\n",
    "y_pred_lreg = log_reg.best_estimator_.predict(X_test_vec)\n",
    "print_metrics(y_pred_lreg, y_test)\n",
    "\n",
    "print()\n",
    "print('Naive Bayes:')\n",
    "y_pred_nb = naive_bayes.predict(X_test_vec)\n",
    "print_metrics(y_pred_nb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Вывод - логистическая регрессия работает лучше </b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
